{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "распознавание одежды.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prog815/lernDLpython/blob/master/%D1%80%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%BE%D0%B4%D0%B5%D0%B6%D0%B4%D1%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaIufbOghIp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import utils\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHx-ViyCiqvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVsB97qxizSt",
        "colab_type": "code",
        "outputId": "d2cc285d-e9ef-4df1-deb4-f5342e14b322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5hZCR8spGaq",
        "colab_type": "code",
        "outputId": "b6626649-16a8-4bfc-951b-17219692ecfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AanuKV7hpQlj",
        "colab_type": "code",
        "outputId": "fcbf28f6-95b6-4641-d45a-8c4359b10922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train = x_train.reshape(60000,28*28)\n",
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3mBPvl_xVek",
        "colab_type": "code",
        "outputId": "1593dbcf-da30-416a-f290-5b4fa328d283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   1,   0,   0,  13,  73,   0,   0,   1,\n",
              "         4,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   3,   0,  36, 136, 127,  62,\n",
              "        54,   0,   0,   0,   1,   3,   4,   0,   0,   3,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0, 102, 204,\n",
              "       176, 134, 144, 123,  23,   0,   0,   0,   0,  12,  10,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "       155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,  72,\n",
              "        15,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "         0,  69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,\n",
              "        88, 172,  66,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "         1,   1,   0, 200, 232, 232, 233, 229, 223, 223, 215, 213, 164,\n",
              "       127, 123, 196, 229,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0, 183, 225, 216, 223, 228, 235, 227, 224,\n",
              "       222, 224, 221, 223, 245, 173,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 193, 228, 218, 213, 198, 180,\n",
              "       212, 210, 211, 213, 223, 220, 243, 202,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   1,   3,   0,  12, 219, 220, 212, 218,\n",
              "       192, 169, 227, 208, 218, 224, 212, 226, 197, 209,  52,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99, 244, 222,\n",
              "       220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119, 167,  56,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
              "       236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
              "        92,   0,   0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,\n",
              "         0, 237, 226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215,\n",
              "       218, 255,  77,   0,   0,   3,   0,   0,   0,   0,   0,   0,   0,\n",
              "        62, 145, 204, 228, 207, 213, 221, 218, 208, 211, 218, 224, 223,\n",
              "       219, 215, 224, 244, 159,   0,   0,   0,   0,   0,  18,  44,  82,\n",
              "       107, 189, 228, 220, 222, 217, 226, 200, 205, 211, 230, 224, 234,\n",
              "       176, 188, 250, 248, 233, 238, 215,   0,   0,  57, 187, 208, 224,\n",
              "       221, 224, 208, 204, 214, 208, 209, 200, 159, 245, 193, 206, 223,\n",
              "       255, 255, 221, 234, 221, 211, 220, 232, 246,   0,   3, 202, 228,\n",
              "       224, 221, 211, 211, 214, 205, 205, 205, 220, 240,  80, 150, 255,\n",
              "       229, 221, 188, 154, 191, 210, 204, 209, 222, 228, 225,   0,  98,\n",
              "       233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217, 241,\n",
              "        65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224, 229,\n",
              "        29,  75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206,\n",
              "       198, 213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220,\n",
              "       221, 230,  67,  48, 203, 183, 194, 213, 197, 185, 190, 194, 192,\n",
              "       202, 214, 219, 221, 220, 236, 225, 216, 199, 206, 186, 181, 177,\n",
              "       172, 181, 205, 206, 115,   0, 122, 219, 193, 179, 171, 183, 196,\n",
              "       204, 210, 213, 207, 211, 210, 200, 196, 194, 191, 195, 191, 198,\n",
              "       192, 176, 156, 167, 177, 210,  92,   0,   0,  74, 189, 212, 191,\n",
              "       175, 172, 175, 181, 185, 188, 189, 188, 193, 198, 204, 209, 210,\n",
              "       210, 211, 188, 188, 194, 192, 216, 170,   0,   2,   0,   0,   0,\n",
              "        66, 200, 222, 237, 239, 242, 246, 243, 244, 221, 220, 193, 191,\n",
              "       179, 182, 182, 181, 176, 166, 168,  99,  58,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0AeKsV7xc8o",
        "colab_type": "code",
        "outputId": "53db1304-0e39-4b83-d358-1ac7e4a8715e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_train = x_train / 255\n",
        "x_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.00392157, 0.        , 0.        , 0.05098039,\n",
              "       0.28627451, 0.        , 0.        , 0.00392157, 0.01568627,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
              "       0.        , 0.14117647, 0.53333333, 0.49803922, 0.24313725,\n",
              "       0.21176471, 0.        , 0.        , 0.        , 0.00392157,\n",
              "       0.01176471, 0.01568627, 0.        , 0.        , 0.01176471,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
              "       0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
              "       0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.04705882, 0.03921569, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.60784314, 0.9254902 , 0.81176471,\n",
              "       0.69803922, 0.41960784, 0.61176471, 0.63137255, 0.42745098,\n",
              "       0.25098039, 0.09019608, 0.30196078, 0.50980392, 0.28235294,\n",
              "       0.05882353, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.00392157, 0.        , 0.27058824,\n",
              "       0.81176471, 0.8745098 , 0.85490196, 0.84705882, 0.84705882,\n",
              "       0.63921569, 0.49803922, 0.4745098 , 0.47843137, 0.57254902,\n",
              "       0.55294118, 0.34509804, 0.6745098 , 0.25882353, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.00392157, 0.00392157,\n",
              "       0.00392157, 0.        , 0.78431373, 0.90980392, 0.90980392,\n",
              "       0.91372549, 0.89803922, 0.8745098 , 0.8745098 , 0.84313725,\n",
              "       0.83529412, 0.64313725, 0.49803922, 0.48235294, 0.76862745,\n",
              "       0.89803922, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.71764706, 0.88235294, 0.84705882, 0.8745098 , 0.89411765,\n",
              "       0.92156863, 0.89019608, 0.87843137, 0.87058824, 0.87843137,\n",
              "       0.86666667, 0.8745098 , 0.96078431, 0.67843137, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
              "       0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
              "       0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
              "       0.95294118, 0.79215686, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.00392157, 0.01176471, 0.        ,\n",
              "       0.04705882, 0.85882353, 0.8627451 , 0.83137255, 0.85490196,\n",
              "       0.75294118, 0.6627451 , 0.89019608, 0.81568627, 0.85490196,\n",
              "       0.87843137, 0.83137255, 0.88627451, 0.77254902, 0.81960784,\n",
              "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.02352941, 0.        , 0.38823529, 0.95686275,\n",
              "       0.87058824, 0.8627451 , 0.85490196, 0.79607843, 0.77647059,\n",
              "       0.86666667, 0.84313725, 0.83529412, 0.87058824, 0.8627451 ,\n",
              "       0.96078431, 0.46666667, 0.65490196, 0.21960784, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.01568627, 0.        ,\n",
              "       0.        , 0.21568627, 0.9254902 , 0.89411765, 0.90196078,\n",
              "       0.89411765, 0.94117647, 0.90980392, 0.83529412, 0.85490196,\n",
              "       0.8745098 , 0.91764706, 0.85098039, 0.85098039, 0.81960784,\n",
              "       0.36078431, 0.        , 0.        , 0.        , 0.00392157,\n",
              "       0.01568627, 0.02352941, 0.02745098, 0.00784314, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.92941176,\n",
              "       0.88627451, 0.85098039, 0.8745098 , 0.87058824, 0.85882353,\n",
              "       0.87058824, 0.86666667, 0.84705882, 0.8745098 , 0.89803922,\n",
              "       0.84313725, 0.85490196, 1.        , 0.30196078, 0.        ,\n",
              "       0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
              "       0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
              "       0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
              "       0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
              "       0.95686275, 0.62352941, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.07058824, 0.17254902, 0.32156863,\n",
              "       0.41960784, 0.74117647, 0.89411765, 0.8627451 , 0.87058824,\n",
              "       0.85098039, 0.88627451, 0.78431373, 0.80392157, 0.82745098,\n",
              "       0.90196078, 0.87843137, 0.91764706, 0.69019608, 0.7372549 ,\n",
              "       0.98039216, 0.97254902, 0.91372549, 0.93333333, 0.84313725,\n",
              "       0.        , 0.        , 0.22352941, 0.73333333, 0.81568627,\n",
              "       0.87843137, 0.86666667, 0.87843137, 0.81568627, 0.8       ,\n",
              "       0.83921569, 0.81568627, 0.81960784, 0.78431373, 0.62352941,\n",
              "       0.96078431, 0.75686275, 0.80784314, 0.8745098 , 1.        ,\n",
              "       1.        , 0.86666667, 0.91764706, 0.86666667, 0.82745098,\n",
              "       0.8627451 , 0.90980392, 0.96470588, 0.        , 0.01176471,\n",
              "       0.79215686, 0.89411765, 0.87843137, 0.86666667, 0.82745098,\n",
              "       0.82745098, 0.83921569, 0.80392157, 0.80392157, 0.80392157,\n",
              "       0.8627451 , 0.94117647, 0.31372549, 0.58823529, 1.        ,\n",
              "       0.89803922, 0.86666667, 0.7372549 , 0.60392157, 0.74901961,\n",
              "       0.82352941, 0.8       , 0.81960784, 0.87058824, 0.89411765,\n",
              "       0.88235294, 0.        , 0.38431373, 0.91372549, 0.77647059,\n",
              "       0.82352941, 0.87058824, 0.89803922, 0.89803922, 0.91764706,\n",
              "       0.97647059, 0.8627451 , 0.76078431, 0.84313725, 0.85098039,\n",
              "       0.94509804, 0.25490196, 0.28627451, 0.41568627, 0.45882353,\n",
              "       0.65882353, 0.85882353, 0.86666667, 0.84313725, 0.85098039,\n",
              "       0.8745098 , 0.8745098 , 0.87843137, 0.89803922, 0.11372549,\n",
              "       0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
              "       0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
              "       0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
              "       0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
              "       0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
              "       0.86666667, 0.90196078, 0.2627451 , 0.18823529, 0.79607843,\n",
              "       0.71764706, 0.76078431, 0.83529412, 0.77254902, 0.7254902 ,\n",
              "       0.74509804, 0.76078431, 0.75294118, 0.79215686, 0.83921569,\n",
              "       0.85882353, 0.86666667, 0.8627451 , 0.9254902 , 0.88235294,\n",
              "       0.84705882, 0.78039216, 0.80784314, 0.72941176, 0.70980392,\n",
              "       0.69411765, 0.6745098 , 0.70980392, 0.80392157, 0.80784314,\n",
              "       0.45098039, 0.        , 0.47843137, 0.85882353, 0.75686275,\n",
              "       0.70196078, 0.67058824, 0.71764706, 0.76862745, 0.8       ,\n",
              "       0.82352941, 0.83529412, 0.81176471, 0.82745098, 0.82352941,\n",
              "       0.78431373, 0.76862745, 0.76078431, 0.74901961, 0.76470588,\n",
              "       0.74901961, 0.77647059, 0.75294118, 0.69019608, 0.61176471,\n",
              "       0.65490196, 0.69411765, 0.82352941, 0.36078431, 0.        ,\n",
              "       0.        , 0.29019608, 0.74117647, 0.83137255, 0.74901961,\n",
              "       0.68627451, 0.6745098 , 0.68627451, 0.70980392, 0.7254902 ,\n",
              "       0.7372549 , 0.74117647, 0.7372549 , 0.75686275, 0.77647059,\n",
              "       0.8       , 0.81960784, 0.82352941, 0.82352941, 0.82745098,\n",
              "       0.7372549 , 0.7372549 , 0.76078431, 0.75294118, 0.84705882,\n",
              "       0.66666667, 0.        , 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.25882353, 0.78431373, 0.87058824, 0.92941176,\n",
              "       0.9372549 , 0.94901961, 0.96470588, 0.95294118, 0.95686275,\n",
              "       0.86666667, 0.8627451 , 0.75686275, 0.74901961, 0.70196078,\n",
              "       0.71372549, 0.71372549, 0.70980392, 0.69019608, 0.65098039,\n",
              "       0.65882353, 0.38823529, 0.22745098, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
              "       0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t7mNi4bpl9w",
        "colab_type": "code",
        "outputId": "133fcb2e-6902-4138-b8ab-cb87e2cd5d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg5mwSMnpslU",
        "colab_type": "code",
        "outputId": "22e12809-0b3a-4f04-bb94-16f43ff150ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train = utils.to_categorical(y_train,10)\n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJilXqS7qLtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(800,input_shape=(784,),activation=\"relu\"))\n",
        "model.add(Dense(10,activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMRkeOwwrxHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import losses\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpRU9GNhuIYQ",
        "colab_type": "code",
        "outputId": "e5d93e71-0add-4b16-e33e-b77087ba19c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"SGD\",metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 800)               628000    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                8010      \n",
            "=================================================================\n",
            "Total params: 636,010\n",
            "Trainable params: 636,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1RHTDYButLD",
        "colab_type": "code",
        "outputId": "a52c1ebc-2d98-42ab-8a63-3d3558e6c09b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train,y_train,batch_size=200,epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1409 - acc: 0.6609\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 0.7252 - acc: 0.7755\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.6339 - acc: 0.8015\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.5849 - acc: 0.8142\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.5533 - acc: 0.8208\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.5305 - acc: 0.8267\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.5133 - acc: 0.8303\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4996 - acc: 0.8335\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4880 - acc: 0.8367\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4786 - acc: 0.8395\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4701 - acc: 0.8405\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4630 - acc: 0.8438\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4567 - acc: 0.8455\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4505 - acc: 0.8466\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4453 - acc: 0.8496\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4402 - acc: 0.8503\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4357 - acc: 0.8510\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4315 - acc: 0.8534\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4281 - acc: 0.8543\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4245 - acc: 0.8553\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4210 - acc: 0.8565\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4173 - acc: 0.8573\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4147 - acc: 0.8589\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4113 - acc: 0.8597\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4087 - acc: 0.8597\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4059 - acc: 0.8610\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4031 - acc: 0.8630\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4011 - acc: 0.8624\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3984 - acc: 0.8632\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3958 - acc: 0.8648\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3937 - acc: 0.8654\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3915 - acc: 0.8660\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3895 - acc: 0.8657\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3873 - acc: 0.8670\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3851 - acc: 0.8685\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3835 - acc: 0.8688\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3815 - acc: 0.8690\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3799 - acc: 0.8698\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3780 - acc: 0.8701\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3759 - acc: 0.8708\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3739 - acc: 0.8719\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3726 - acc: 0.8724\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3708 - acc: 0.8735\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3688 - acc: 0.8731\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3678 - acc: 0.8737\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3658 - acc: 0.8741\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3644 - acc: 0.8751\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3631 - acc: 0.8751\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3617 - acc: 0.8762\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3604 - acc: 0.8761\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3589 - acc: 0.8764\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3573 - acc: 0.8767\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3561 - acc: 0.8770\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.3546 - acc: 0.8781\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3533 - acc: 0.8787\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3523 - acc: 0.8789\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3505 - acc: 0.8783\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3491 - acc: 0.8798\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3483 - acc: 0.8797\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3468 - acc: 0.8802\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3456 - acc: 0.8810\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3446 - acc: 0.8810\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3433 - acc: 0.8812\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3419 - acc: 0.8826\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3408 - acc: 0.8819\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3392 - acc: 0.8827\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3385 - acc: 0.8821\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3372 - acc: 0.8836\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3365 - acc: 0.8839\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3352 - acc: 0.8844\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3342 - acc: 0.8848\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.3331 - acc: 0.8848\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3320 - acc: 0.8854\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3314 - acc: 0.8851\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3300 - acc: 0.8861\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3293 - acc: 0.8861\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3283 - acc: 0.8860\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3272 - acc: 0.8870\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3261 - acc: 0.8869\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3254 - acc: 0.8863\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3243 - acc: 0.8875\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3234 - acc: 0.8874\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3227 - acc: 0.8877\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3215 - acc: 0.8883\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3203 - acc: 0.8883\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3195 - acc: 0.8895\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3181 - acc: 0.8893\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3173 - acc: 0.8896\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3162 - acc: 0.8902\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3157 - acc: 0.8906\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3146 - acc: 0.8900\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3141 - acc: 0.8910\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3136 - acc: 0.8910\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3123 - acc: 0.8913\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3112 - acc: 0.8916\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3107 - acc: 0.8923\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3103 - acc: 0.8926\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3091 - acc: 0.8927\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3083 - acc: 0.8931\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3074 - acc: 0.8932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f51c00cff98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_jJTT2Ev4zu",
        "colab_type": "code",
        "outputId": "edeb3109-dc0c-4ed1-86c6-6a0a70ad35ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4t7AQqNyUKz",
        "colab_type": "code",
        "outputId": "b485ecd4-7c72-4a62-af70-f63c300291ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction=model.predict(x_test.reshape(10000,28*28)/255)\n",
        "prediction.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7cuT-hczRH0",
        "colab_type": "code",
        "outputId": "b3f7da8e-dcc1-40b1-9977-cb15fe3a0af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "prediction[5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.4425754e-03, 9.9380189e-01, 4.2652281e-04, 5.3096632e-04,\n",
              "       7.1410433e-04, 4.4599666e-10, 6.0700888e-05, 3.7939103e-08,\n",
              "       2.3299262e-05, 3.4943504e-10], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkfdmwi-zWBZ",
        "colab_type": "code",
        "outputId": "c370a3dd-990a-464e-e19c-323ce62eb853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test[5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrcBHM8izhLh",
        "colab_type": "code",
        "outputId": "af1cb440-e3fa-4a4d-cc33-138760721727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n=1000\n",
        "np.argmax(prediction[n]),y_test[n]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV09VupAz4sN",
        "colab_type": "code",
        "outputId": "845e00b3-33bd-4446-f9fa-11ff8f1076bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "res = 0\n",
        "for n in range(len(y_test)):\n",
        "  if np.argmax(prediction[n])==y_test[n]:\n",
        "    res += 1\n",
        "res"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8712"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSoFHsE204Bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}